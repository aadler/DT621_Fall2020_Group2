---
title: "shamp_ensemble_model"
author: "Jeff Shamp"
date: "9/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)
```

```{r, message=FALSE}
library(tidyverse)
library(tidymodels)
library(stacks)
library(kernlab)
library(vip)
set.seed(9450)
```


```{r}
crime_df<- read.csv("https://raw.githubusercontent.com/aadler/DT621_Fall2020_Group2/master/HW3/data/crime-training-data_modified.csv")
crime_df<- as_tibble(crime_df)
```

## Model Specifics and Training Scheme

We will split the training data into two sets and perform a cross validation scheme on the models to tune parameters for optimum performance. Once we have the best models we will blend the logistic regression with another top model to boost performance. 

```{r}
crime_df<-
  crime_df %>% 
  mutate(target = as.factor(target)) %>% 
  mutate_if(is.integer, as.numeric)

data_split <- initial_split(crime_df, 
                            strata = target, 
                            prop = 0.8)
train_df<- training(data_split)
test_df<- testing(data_split)
```

Cross validation and workflow creation. 

```{r}
cv_folds<- vfold_cv(train_df,
                    v = 10, repeats = 1)

crime_recipe<- 
  recipe(target ~., data=train_df)


crime_wf<- 
  workflow() %>%
  add_recipe(crime_recipe)

crtl_grid<- control_stack_grid()
```

Specify the models. Using SVM as another model to blend with the logistic. 

```{r}
logit_specs<- 
  logistic_reg(
    penalty = tune(),
    mixture = tune()
    ) %>%
  set_engine("glm") %>%
  set_mode("classification")

# rf_specs<-
#   rand_forest(
#     min_n = tune(),
#     mtry = tune(),
#     trees = tune()
#   ) %>%
#   set_engine("ranger") %>%
#   set_mode("classification")

svm_specs<- 
  svm_rbf(
    cost = tune(),
    rbf_sigma = tune(),
    margin = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("kernlab")
```

Tuning the models for best parameters. The stack function will cherry pick the models that best optimize the blended final model. 

```{r}
svm_wf<-
  crime_wf %>%
  add_model(svm_specs)

svm_results<-
  tune_grid(
    svm_wf, 
    resample = cv_folds,
    control = crtl_grid,
    grid = 10,
    save_pred = TRUE,
    save_workflow = FALSE
  )

logit_wf<- 
  crime_wf %>%
  add_model(logit_specs)

logit_results<-
  tune_grid(
    logit_wf,
    resamples = cv_folds,
    control = crtl_grid,
    grid = 10,
    save_pred = TRUE,
    save_workflow = FALSE
)

# rf_wf<-
#   crime_wf %>%
#   add_model(rf_specs)
# 
# rf_results<-
#   tune_grid(
#     rf_wf, 
#     resamples = cv_folds,
#     control = crtl_grid, 
#     grid =10
#   )
```

Blend!

```{r}
crime_model_stack <- 
  stacks() %>%
  add_candidates(logit_results) %>%
  add_candidates(svm_results) %>%
  blend_predictions() %>%
  fit_members()

crime_model_stack
```

We see that the logistic classifier is the top weight in the blended model, with the support vector machine...supporting the classification results. 

```{r}
theme_set(theme_bw())
autoplot(crime_model_stack)
```



```{r}
crime_pred <- 
  test_df %>%
  bind_cols(predict(crime_model_stack, ., type = "prob"), 
            predict(crime_model_stack, ., type = "class"))
```

Computing the metrics for the stacked model:

```{r}
roc<- yardstick::roc_auc(
  crime_pred,
  truth = target,
  contains(".pred_1")
  )

acc<- yardstick::accuracy(
  crime_pred, 
  truth = target, 
  estimate = .pred_class
)

recall<- yardstick::recall(
  crime_pred,
  truth = target, 
  estimate = .pred_class
)

precise<- yardstick::precision(
  crime_pred,
  truth = target, 
  estimate = .pred_class
)
metrics_df<-
  bind_rows(roc, acc, recall, precise)

crime_pred %>%
  conf_mat(truth = target, estimate = .pred_class)
```




```{r}
metrics_df
```

### Sub-Models

The blended model is comprised of two sub-models, the logistic and the SVM. Below are the prediction results for each sub-model. 

```{r}
best_model_metric <- select_best(svm_results, "accuracy")
finalize_workflow(svm_wf, best_model_metric) %>%
  last_fit(data_split) %>%
  collect_metrics()
```



```{r}
logit_wf %>%
  last_fit(data_split) %>%
  collect_metrics()

logit_wf %>%
  fit(data = train_df) %>%
  pull_workflow_fit() %>%
  vip(geom = "col", aesthetics = list(fill='red4'))
```
We see that they are both in the low eighties percent for accuracy, and low nineties for roc auc. Together make for a better overall prediction. 

## Test Predictions

```{r}
eval_df<- read.csv("https://raw.githubusercontent.com/aadler/DT621_Fall2020_Group2/master/HW3/data/crime-evaluation-data_modified.csv")
eval_df<-as.tbl(eval_df)
```



```{r}
eval_pred <- 
  eval_df %>%
  bind_cols(predict(crime_model_stack, ., type = "prob"), 
            predict(crime_model_stack, ., type = "class"))
```



```{r}
bind_cols(
eval_pred %>%
  filter(.pred_class == 0) %>%
  count(name = "negative"),
eval_pred %>%
  filter(.pred_class ==1) %>%
  count(name = "positive")
)
```



