---
title: "DATA 621 - Business Analytics and Data Mining"
subtitle: 'Fall 2020 - Group 2 - Homework #4'
author: Avraham Adler, Samantha Deokinanan, Amber Ferger, John Kellogg,
    Bryan Persaud, Jeff Shamp
date: "11/01/2020"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 4
urlcolor: purple
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE)
```

```{r loadData, include=FALSE}
# Load necessary libraries
library(corrplot)
library(ggplot2)
library(scales)
library(knitr)
library(caret)
library(RANN)
library(pROC)
library(data.table)
# Set master seed
set.seed(71554)

# Set filepaths for data ingestion
urlRemote  = "https://raw.githubusercontent.com/"
pathGithub = "aadler/DT621_Fall2020_Group2/master/HW4/data/"
fileTrain = "insurance_training_data.csv"
fileTest = "insurance-evaluation-data.csv"

# Read training file
DT <- fread(paste0(urlRemote, pathGithub, fileTrain),
            colClasses = c(rep('integer', 2L), 'double', rep('integer', 4L),
                           'double', 'factor', 'double', rep('factor', 4L),
                           'integer', 'factor', 'double', 'integer',
                           rep('factor', 2L), 'double', 'integer', 'factor',
                           rep('integer', 2L), 'factor'))

# Convert character currencies to doubles
DT[, `:=`(INCOME = as.double(gsub('[$,]', '', INCOME)),
          HOME_VAL = as.double(gsub('[$,]', '', HOME_VAL)),
          BLUEBOOK = as.double(gsub('[$,]', '', BLUEBOOK)),
          OLDCLAIM = as.double(gsub('[$,]', '', OLDCLAIM)))]

# Read and process the test/evaluation file
eval <- fread(paste0(urlRemote, pathGithub, fileTest),
              colClasses = c(rep('integer', 2L), 'double', rep('integer', 4L),
                             'double', 'factor', 'double', rep('factor', 4L),
                             'integer', 'factor', 'double', 'integer',
                             rep('factor', 2L), 'double', 'integer', 'factor',
                             rep('integer', 2L), 'factor'))
eval[, `:=`(INCOME = as.double(gsub('[$,]', '', INCOME)),
          HOME_VAL = as.double(gsub('[$,]', '', HOME_VAL)),
          BLUEBOOK = as.double(gsub('[$,]', '', BLUEBOOK)),
          OLDCLAIM = as.double(gsub('[$,]', '', OLDCLAIM)))]

# Number of training observations
ntrobs <- dim(DT)[[1]]

# Get the names of the variables and which ones are numeric
nmtrn <- names(DT)
nmtrnNUM <- names(DT[, .SD, .SDcols = sapply(DT, is.numeric)])
nmtrnDUB <- names(DT[, .SD, .SDcols = sapply(DT, is.double)])
nmtrnFAC <- setdiff(nmtrn, nmtrnNUM)
# Drop INDEX and target variablesfrom name list
nmtrnNUM <- nmtrnNUM[-(1:3)]
```

# Introduction
The assignment for HW4 is to analyze and model a dataset containing
approximately 8000 records representing customers of an auto insurance company.
Each record has two response variables. The first response variable,
`TARGET_FLAG`, is a 1 or a 0. where a `1` means that the person was in a car
and a `0` means that the person was not in a car crash. The second response
variable is `TARGET_AMT`. This value is 0 if the person did not crash their car.
However, if they did crash their car, this number will be a value greater than
zero.

The objective of the assignment is to build multiple linear regression and
binary logistic regression models on the training data to predict **both** the
probability that a person will crash their car and the amount of money it will
cost given a crash. Only the variables in the dataset, or variables directly
derived from them, may be used.

# DATA EXPLORATION
## Variables
The data is composed of the following variables:

|VARIABLE NAME|DEFINITION|THEORETICAL EFFECT|
|-|-|-|
|INDEX|Identification Variable (do not use)|None|
|TARGET_FLAG|Was Car in a crash? 1=YES 0=NO|None|
|TARGET_AMT|If car was in a crash, what was the cost|None|
|AGE|Age of Driver|Very young people tend to be risky. Maybe very old people also.|
|BLUEBOOK|Value of Vehicle|Unknown effect on probability of collision, but probably effect the payout if there is a crash|
|CAR_AGE|Vehicle Age|Unknown effect on probability of collision, but probably effect the payout if there is a crash|
|CAR_TYPE|Type of Car|Unknown effect on probability of collision, but probably effect the payout if there is a crash|
|CAR_USE|Vehicle Use|Commercial vehicles are driven more, so might increase probability of collision|
|CLM_FREQ|# Claims (Past 5 Years)|The more claims you filed in the past, the more you are likely to file in the future|
|EDUCATION|Max Education Level|Unknown effect, but in theory more educated people tend to drive more safely|
|HOMEKIDS|# Children at Home|Unknown effect|
|HOME_VAL|Home Value|In theory, home owners tend to drive more responsibly|
|INCOME|Income|In theory, rich people tend to get into fewer crashes|
|JOB|Job Category|In theory, white collar jobs tend to be safer|
|KIDSDRIV|# Driving Children|When teenagers drive your car, you are more likely to get into crashes|
|MSTATUS|Marital Status|In theory, married people drive more safely|
|MVR_PTS|Motor Vehicle Record Points|If you get lots of traffic tickets, you tend to get into more crashes|
|OLDCLAIM|Total Claims (Past 5 Years)|If your total payout over the past five years was high, this suggests future payouts will be high|
|PARENT1|Single Parent|Unknown effect|
|RED_CAR|A Red Car|Urban legend says that red cars (especially red sports cars) are more risky. Is that true?|
|REVOKED|License Revoked (Past 7 Years)|If your license was revoked in the past 7 years, you probably are a more risky driver.|
|SEX|Gender|Urban legend says that women have less crashes then men. Is that true?|
|TIF|Time in Force|People who have been customers for a long time are usually more safe.|
|TRAVTIME|Distance to Work|Long drives to work usually suggest greater risk|
|URBANICITY|Home/Work Area|Unknown|
|YOJ|Years on Job|People who stay at a job for a long time are usually more safe|

There are `r ntrobs` observations of `r length(nmtrnNUM) - 2` numeric predictor
variables and `r length(nmtrnFAC)` factor predictor variables.

## Missing Data
There are missing observations. Specifically, the following variables have
missing values coded as `NA`:

```{r missingVal}
# Check for NAs in all variables
missingV <- DT[, lapply(.SD, function(x) sum(is.na(x)))]
# Only keep those whose count is > 0
missingV <- missingV[, .SD, .SDcols = sapply(missingV, function (x) x > 0)]
kable(missingV, caption = "Variables with Count of Missing Values > 0")
```

Another concern is that the following variables should not have significant
probabilities of 0 because they represent values which *should* be positive:

  * AGE
  * YOJ
  * INCOME
  * HOME_VAL
  * TRAVTIME
  * BLUEBOOK
  * TIF
  * CAR_AGE

```{r zeroVal}
# Check for 0 value for the above variables
zeroV <- DT[, lapply(.SD, function(x) sum(x == 0, na.rm = TRUE)),
            .SDcols = c('AGE', 'YOJ', 'INCOME', 'HOME_VAL', 'TRAVTIME',
                        'BLUEBOOK', 'TIF', 'CAR_AGE')]
# Only keep those whose count of zero values is > 0
zeroV <- zeroV[, .SD, .SDcols = sapply(zeroV, function (x) x > 0)]
kable(zeroV, caption = "Variables with Count of Missing Values > 0")
```

The few missing `CAR_AGE` values should be easy to impute. The other heavy-0
observations are of more concern. Over 25% of the `HOME_VAL` observations are 0!
Now it may be that those with `HOME_VAL` of 0 do not own homes but rent, and it
may be that those with `YOJ` and `INCOME` of 0 were unemployed at the time of
the data collection. There are `r DT[YOJ == 0 & INCOME == 0, .N]` observations
with both `YOJ` and `INCOME` of 0, meaning there are a few dozen of each which
have values in one class and not the other. Handling this will be addressed in
the DATA PREPARATION section.

## Summary Statistics and Graphs
### Numeric Predictors
The numeric predictor variables have the following summary statistics, ignoring
missing values:

```{r statsN}
# Isolate numeric only predictors
numDT <- DT[, .SD, .SDcols = nmtrnNUM]

# Melt them from wide to long format
numDTM <- melt(numDT, variable.name = 'metric', value.name = 'value')

# Calculate summary statistics
statsN <- numDTM[, .(Mean = mean(value, na.rm = TRUE),
                     SD = sd(value, na.rm = TRUE),
                     Min = min(value, na.rm = TRUE),
                     Q1 = quantile(value, prob = 0.25, na.rm = TRUE),
                     Median = median(value, na.rm = TRUE),
                     Q3 = quantile(value, prob = 0.75, na.rm = TRUE),
                     Max = max(value, na.rm = TRUE),
                     IQR = IQR(value, na.rm = TRUE)), keyby = 'metric']

# Print the table
kable(statsN, digits = 3L, align = 'r',
      caption = "Summary Statistitics for Numeric Variables")
```

A visual depiction of the distributions of the numeric predictors follows. The
blue graphs are on a normal scale and the red ones are on a \(\log_{10}\) scale.

```{r graphsN}
# Freedman-Diaconis rule for bin widths
FDbin <- function(x) {
  result <- 2 * IQR(x, na.rm = TRUE) / (length(x) ^ (1 / 3))
  return(ifelse(result == 0, 0.5, result))
}
ggplot(numDTM[!is.na(metric)], aes(x = value)) +
  geom_histogram(binwidth = FDbin, fill = 'lightblue3') +
  facet_wrap( ~ metric, scales = 'free')

ggplot(numDTM, aes(x = value)) +
  geom_histogram(binwidth = FDbin, fill = 'indianred4') +
  facet_wrap( ~ metric, scales = 'free') + scale_x_log10()
```

What the above visualizations show is that there are two sets of numeric
variables. There are those which are clearly discrete, taking one of a few
integral values, and there are those which are more continuous. Of the
continuous variables, some like `AGE` look rather Gaussian at first glance,
while others, such as `HOME_VAL` or `INCOME` are skewed. However, `HOME_VAL`
looks lognormal, as its histogram on the log scale is near-Gaussian.

A variable such as `OLDCLAIM` is expected to have a mass point at 0. Every
observation which had fewer than 2 claims clearly did not have a prior claim!

### Factor Predictors
While tabular depiction of factor variables is usually of little value, visual
representation of their distributions is of use.

```{r graphsF, fig.width=8, fig.height=8}
# Isolate factor only predictors
facDT <- DT[, .SD, .SDcols = nmtrnFAC]

# Melt them from wide to long format (need to explicitly call measure.vars since
# these are all factors)
facDTM <- melt(facDT, measure.vars = nmtrnFAC, variable.name = 'metric',
               value.name = 'value')
ggplot(facDTM, aes(x = value)) + geom_bar(fill = 'darkolivegreen') +
  facet_wrap( ~ metric, nrow = 5L, scales = 'free') + coord_flip()
```

In order to use regression-based tools, we are going to have to convert these
factors to dummy variables. Another important observation is that there are
rows for which `JOB` is blank and some strange value names for some of the
factors. Cleaning this up will be handled in the DATA PREPARATION section.

### Correlations
The corrgram below graphically represents the correlations between the numeric
predictor variables, when ignoring the missing variables.

```{r corrgram, fig.width=6, fig.height=4}
corrplot(cor(DT[, ..nmtrnNUM], use = 'complete.obs'),
         method = 'ellipse', type = 'lower')
```

Most of the numeric variables are uncorrelated with one another. A few
exceptions exist:

 * `HOMEKIDS` with `KIDSDRIV`
   * This is self-explanatory
 * `HOME_VAL` with `INCOME`
   * Both are very strongly tied to wealth and net worth
 * `BLUEBOOK` and `INCOME`
   * People with more disposable income can afford more expensive vehicles
 * `CLM_FREQ` with `OLDCLAIM`
   * More claims implies a greater total aggregate payment
 * `CAR_AGE` and `INCOME`
   * This is interesting. It could be that people with higher disposable incomes
   buy more expensive cars and keep them for longer, but that's a guess.
 * `MVR_PTS` is *lightly* correlated with `CLM_FREQ` and `OLDCLAIM`
   * Probably when one is in a lot of accidents, the chances of them being at
   some level of fault rises
 * `HOMEKIDS` **negatively** correlated with `AGE`
   * As people age, their children age as well and eventually move out, we hope!

# DATA PREPARATION
## Data Value Cleanup
The first step will be to clean up the strange values and blank `JOB` entries.

```{r dataClean}
# Clean up data values. Using setattr for fast data.table setting. Equivalent
# to levels(DT$X) <- c(a, b) but faster since changes by reference.
# Remove spaces where possible too
setattr(DT$MSTATUS, 'levels', c('Yes', 'No'))
setattr(DT$SEX, 'levels', c('M', 'F'))
setattr(DT$EDUCATION, 'levels', c('<HighSchool', 'Bachelors', 'Masters', 'PhD',
                                  'HighSchool'))
setattr(DT$JOB, 'levels', c('Unknown', 'Clerical', 'Doctor', 'HomeMaker',
                            'Lawyer', 'Manager', 'Professional', 'Student',
                            'BlueCollar'))
setattr(DT$CAR_TYPE, 'levels', c('Minivan', 'PanelTruck', 'Pickup',
                                 'SportsCar', 'Van', 'SUV'))

setattr(DT$URBANICITY, 'levels', c('Urban', 'Rural'))

# Relevel some of the variables to have the default make more sense
# Set default marital status to unmarried
set(DT, NULL, 'MSTATUS', relevel(DT$MSTATUS, 'No'))
# Set default car usage to private
set(DT, NULL, 'CAR_USE', relevel(DT$CAR_USE, 'Private'))
# Set default are to rural, making urban a positive? risk factor
set(DT, NULL, 'URBANICITY', relevel(DT$URBANICITY, 'Rural'))
```

## Training & Testing Split
While the following discussion more properly occurs under BUILD MODELS, as it
factors into how the data is prepared, it will happen here. All the models will
be trained on the same approximately 70% of the training set, reserving 30% for
validation of which model to select for the frequency and severity estimation on
the supplied evaluation set.

However, there will need to be two sets of training and testing, as the severity
model must perforce be trained on data for which a claim occurred. To maintain
integrity, the split of all the data for frequency will be honored for severity.
The 70/30 split will be honored as all claims with a `TARGET_FLAG` of 1 will
have non-zero `TARGET_AMT`, However, there will be no guarantee that the
*distribution* of the loss conditional on event in the validation set will be
similar to the training set as a whole.

```{r trainTestSplit}
set.seed(642)
trnIDX <- createDataPartition(DT$TARGET_FLAG, p = 0.7)
trnX <- DT[trnIDX$Resample1, ]
tstX <- DT[!trnIDX$Resample1, ]
```

## Models Set 1
### Missing Data
The issues with factor data were handled universally for all models through
resetting the levels. What remains is handling the missing numeric values. For
`CAR_AGE` simple k-means imputation will be used. The remaining three problem
variables, `YOJ`, `INCOME`, and `HOME_VAL` have both `NA` and 0 issues. 

For `YOJ` and `INCOME`, it is not unreasonable to consider 0 to be realistic:
unemployed or employed less than half a year. As such, we will leave the 0's and
impute the NAs.

We will take a different approach with `HOME_VAL`. As seen above when the 0
values are removed, `HOME_VAL` has a nice lognormal shape. It is also reasonable
to consider that people responding with 0 for `HOME_VAL` are non-owners as
opposed to it being missing, although we would want to investigate this further
were we allowed. Therefore, we are going to add a "Own" variable which will be
`Yes` for all positive `HOME_VAL` and `No` otherwise, and allow an interaction
between this value and the actual value. This would be much more effective in a
decision tree framework, but that is not available.

```{r model1addVars}
# Add OWN variable for model set 1
trnX[, OWN := factor(ifelse(HOME_VAL > 0, 1, 0),
                     levels = c(0, 1), labels = c('No', 'Yes'))]
tstX[, OWN := factor(ifelse(HOME_VAL > 0, 1, 0),
                     levels = c(0, 1), labels = c('No', 'Yes'))]
```

# BUILD MODELS
## Model Set 1
### Dummy Variables
As there are many factor variables, dummy variables will be created. The target
variables will be removed and held to the side so as not to contaminate the
fitting.

### Frequency Model
The frequency model will be a binary logistic on the prepared data. It will
start with the complete model and allow for some interactions. It will use both
forward and backward steps to identify which variables to include, using AIC as
the test metric. Using this approach does not allow for cross-validation. The
initial interactions considered will be:

 * `OWN` with `HOME_VAL` as discussed in the missing data section
 * `KIDSDRIV` with `HOMEKIDS`
 * A three-way interaction between `HOME_VAL`, `INCOME`, and `BLUEBOOK`
 * `CLM_FREQ` with `OLDCLAIM`
 * `MSTATUS` with `SEX`
   * One sex may be more affected by marriage than the other
 * `CAR_USE` with `URBANICITY`
 
```{r model1DummyFreq}
# Cast target as factor for caret purposes
trnFreq <- factor(trnX$TARGET_FLAG, levels = c(0, 1),
                  labels = c("NoClaim", "Claim"))
# Set up dummy variables
trnDumFreq <- dummyVars(TARGET_FLAG ~ . + OWN * HOME_VAL + KIDSDRIV * HOMEKIDS +
                          HOME_VAL * INCOME * BLUEBOOK + CLM_FREQ * OLDCLAIM +
                          MSTATUS * SEX + CAR_USE * URBANICITY - INDEX -
                          TARGET_AMT,
                        fullRank = TRUE, data = trnX)
# Create matrix of dummy values
trnXFD <- predict(trnDumFreq, newdata = trnX)
```

#### Training
At this point the code will be set up to preprocess the data and train the
model. The two pre-processing steps which will be done will be to check for
near-zero variance between the predictors and then use kNN imputations for
missing values. Even though the `caret` package allows the preprocessing to
occur in the call to `train`, it will be seperated here for clarity. The actual
code may be found in the CODE APPENDIX.

```{r model1RunFreq, cache=TRUE}
# preProcess with near-zero value and kNN imputation
trnXFDpp <- preProcess(trnXFD, method = c('nzv', 'knnImpute'),
                       k = 3, knnSummary = median)

# Create processed predictors
trnXFDI <- predict(trnXFDpp, newdata = trnXFD)
trC <- trainControl(method = 'none',            # Using StepAIC
                    classProbs = TRUE,          # Classification
                    summaryFunction = prSummary # Precision/Recall
)
set.seed(487)
# Train Model
m1FreqFit <- train(x = trnXFDI, y = trnFreq, trControl = trC,
                   method = 'glmStepAIC', family = binomial(link = 'logit'),
                   direction = 'both', trace = 0)
# Print results
kable(summary(m1FreqFit$finalModel)$coefficients, digits = 3L,
      caption = "Model 1 Frequency Regression Output")
```

#### Coefficient Discussion
It is difficult to directly map the predictors to probabilities, as all the
values have been centered and scaled in order to perform the imputation.
However, we can say that positive coefficients represent an **increased** risk
of a claim over the baseline and negative coefficients represent a **decreased**
risk under the baseline. When validating and then testing, the same imputations
will be done and the results will be predicted on the normal probability scale.

Most of the coefficients are of the expected direction. For example, having
one's license revoked, living in an urban area, or increased travel times are
all *positive* risk factors while higher levels of wealth or education are
*negative* risk factors.

Some interesting observations. The predictors with the greatest effect on risk
are `URBANICITY` and `INCOME`. The value of the coefficient for `SEX` implies
that being female decreases the probability of a claim, as suspected, but it is
only significant as a predictor at the 10% level. However, it is kept in the
model as removing it increases the AIC. The hypothesized interaction between
`MSTATUS` and `SEX` does lower the deviance, but not enough to justify the
additional parameter. `BLUEBOOK` value is a negative risk factor. Perhaps people
with more expensive cars drive more carefully?

The full three-way interaction between `HOME_VAL`, `INCOME`, and `BLUEBOOK` was
deemed insignificant in light of the existing two-way interactions which are in
the model.

The interaction between `CLM_FREQ` and `OLDCLAIM` did help the model AIC, and
the coefficient indicates that while `OLDCLAIM` did not justify the additional
parameter, its tempering of `CLM_FREQ` **does** justify the additional
parameter.

The interaction between `CAR_USE` and `URBANICITY` is also of interest. It
indicates that commercial use vehicles don't really add to claim frequency in
rural areas---the singleton variable is absent from the model---but they have
an outsized influence on increased claim probabilities in urban areas!

#### Variable Importance
In terms of variable importance, it can be estimated from the the last trace of
the stepping procedure shown below. The further down the table the variable is,
the more dramatic its inclusion or exclusion will be on the deviance and theAIC.
The top 10 variables in order would be: `URBANICITY.Urban`,
`CAR_USECommercial:URBANICITYUrban`, `REVOKED.Yes`, `TRAVTIME`,
`CAR_TYPE.Sports Car`, `CLM_FREQ`, `TIF`, `MVR_PTS`, `CAR_TYPE.SUV`,
and `JOB.Blue Collar`.

```
                                      Df Deviance    AIC
<none>                                     5152.3 5212.3
+ HOMEKIDS                             1   5150.5 5212.5
+ AGE                                  1   5150.8 5212.8
+ EDUCATION.Masters                    1   5151.0 5213.0
- SEX.F                                1   5155.2 5213.2
+ JOB.Manager                          1   5151.6 5213.6
+ OLDCLAIM                             1   5151.6 5213.6
+ EDUCATION.PhD                        1   5151.7 5213.7
+ `HOME_VAL:BLUEBOOK`                  1   5151.7 5213.7
+ CAR_AGE                              1   5151.8 5213.8
- `INCOME:BLUEBOOK`                    1   5155.9 5213.9
+ OWN.Yes                              1   5152.1 5214.1
+ `MSTATUSYes:SEXF`                    1   5152.2 5214.2
+ RED_CAR.yes                          1   5152.3 5214.3
+ `EDUCATION.High School`              1   5152.3 5214.3
+ YOJ                                  1   5152.3 5214.3
+ `INCOME:HOME_VAL:BLUEBOOK`           1   5152.3 5214.3
+ CAR_USE.Commercial                   1   5152.3 5214.3
- `INCOME:HOME_VAL`                    1   5158.7 5216.7
- JOB.Student                          1   5159.0 5217.0
- JOB.Lawyer                           1   5159.1 5217.1
- `CAR_TYPE.Panel Truck`               1   5160.0 5218.0
- MSTATUS.Yes                          1   5162.6 5220.6
- CAR_TYPE.Van                         1   5166.3 5224.3
- BLUEBOOK                             1   5166.6 5224.6
- `JOB.Home Maker`                     1   5166.7 5224.7
- `OLDCLAIM:CLM_FREQ`                  1   5167.4 5225.4
- EDUCATION.Bachelors                  1   5169.0 5227.0
- HOME_VAL                             1   5169.5 5227.5
- PARENT1.Yes                          1   5169.9 5227.9
- INCOME                               1   5170.3 5228.3
- CAR_TYPE.Pickup                      1   5170.6 5228.6
- JOB.Professional                     1   5174.0 5232.0
- JOB.Clerical                         1   5181.7 5239.7
- KIDSDRIV                             1   5186.1 5244.1
- `JOB.Blue Collar`                    1   5189.2 5247.2
- CAR_TYPE.SUV                         1   5189.8 5247.8
- MVR_PTS                              1   5191.2 5249.2
- TIF                                  1   5191.8 5249.8
- CLM_FREQ                             1   5193.0 5251.0
- `CAR_TYPE.Sports Car`                1   5195.8 5253.8
- TRAVTIME                             1   5198.9 5256.9
- REVOKED.Yes                          1   5220.1 5278.1
- `CAR_USECommercial:URBANICITYUrban`  1   5229.9 5287.9
- URBANICITY.Urban                     1   5422.8 5480.8
```

### Severity Model
In the insurance world, severity is not necessarily fit via linear models, but
is more often fit through comparison of the maximum likelihood fits of various
distributional families to the size of the claims, but the task here is to fit a
linear regression model to estimate future claim size.

#### Training
The observations in the training set which have claim amounts greater than 0
will be extracted and used to fit the linear regression. Similar to frequency,
the model will be selected via a forward and backward stepwise AIC algorithm
starting with the same predictors and interactions as in the frequency model.

```{r model1DummySev}
# Extract those observations with values > 0
trnSev <- trnX[TARGET_AMT > 0, TARGET_AMT]
# Set up dummy variables
trnDumSev <- dummyVars(TARGET_AMT ~ . + OWN * HOME_VAL + KIDSDRIV * HOMEKIDS +
                          HOME_VAL * INCOME * BLUEBOOK + CLM_FREQ * OLDCLAIM +
                          MSTATUS * SEX + CAR_USE * URBANICITY - INDEX -
                          TARGET_FLAG,
                        fullRank = TRUE, data = trnX[TARGET_AMT > 0])
# Create matrix of dummy values
trnXSD <- predict(trnDumSev, newdata = trnX[TARGET_AMT > 0])
# preProcess with near-zero value and kNN imputation
trnXSDpp <- preProcess(trnXSD, method = c('nzv', 'knnImpute'),
                       k = 3, knnSummary = median)

# Create processed predictors
trnXSDI <- predict(trnXSDpp, newdata = trnXSD)
```

```{r runModel1Sev}
trC <- trainControl(method = 'none')
set.seed(878)
m1SevFit <- train(x = trnXSDI, y = trnSev, trControl = trC,
                  method = 'glmStepAIC', family = gaussian, direction = 'both',
                  trace = 0)
kable(summary(m1SevFit)$coefficients, digits = 3L,
      caption = "Model 1 Severity Regression Output")
```

#### Coefficient Disucssion
It is not surprising that this model has many fewer predictors. Information
which helps in identifying the *existence* of a claim often does not help in
estimating the *magnitude* of the claim.

Similar to the frequency model, it is difficult to directly map the predictors
to claim values, as all the values have been centered and scaled in order to
perform the imputation. However, we can say that positive coefficients represent
**increased** claim sizes over the baseline and negative coefficients represent
**decreased** claim sizes under the baseline. When validating and then testing,
the same imputations will be done and the results will be predicted on the
normal dollar scale.

The predictive variables with the greatest effect on claim size are `OLD_CLAIM`,
`HOME_VAL`, and `BLUEBOOK`. The first and third make the most sense. One who has
had larger claims in the past is likely to have larger claims in the future.
Also, the claim for damages is very strongly correlated with the value of the
vehicle. `HOME_VAL` is a bit strange. Perhaps it's serving as a proxy for
purchased coverage limit. Maybe people with more expensive homes, who buy larger
limits on their homeowners policies, also purchase larger limits on their
vehicular polices.

The interaction between `INCOME` and `HOME_VAL` serves to temper the effect of
`HOME_VAL`. Similarly for the interaction between `OLDCLAIM` and `CLM_FREQ`.

#### Variable Importance
In terms of variable importance, it can be estimated from the the last trace of
the stepping procedure shown below. There are only eight variables in the model,
and in order of AIC contribution they are `BLUEBOOK`, `OLDCLAIM`, `HOME_VAL`,
`INCOME:HOME_VAL`, `CAR_USE.Commercial`, `OLDCLAIM:CLM_FREQ`, `MSTATUS.Yes`, and
` REVOKED.Yes`.

```
                                      Df   Deviance   AIC
<none>                                   9.5456e+10 31329
- REVOKED.Yes                          1 9.5604e+10 31329
+ JOB.Manager                          1 9.5357e+10 31329
- MSTATUS.Yes                          1 9.5620e+10 31330
+ CAR_AGE                              1 9.5370e+10 31330
+ `MSTATUSYes:SEXF`                    1 9.5382e+10 31330
- `OLDCLAIM:CLM_FREQ`                  1 9.5636e+10 31330
- CAR_USE.Commercial                   1 9.5639e+10 31330
+ SEX.F                                1 9.5389e+10 31330
+ JOB.Professional                     1 9.5391e+10 31330
+ CAR_TYPE.Pickup                      1 9.5400e+10 31330
+ MVR_PTS                              1 9.5402e+10 31330
+ CAR_TYPE.Van                         1 9.5403e+10 31330
+ HOMEKIDS                             1 9.5404e+10 31330
+ CLM_FREQ                             1 9.5420e+10 31330
+ `CAR_USECommercial:URBANICITYUrban`  1 9.5426e+10 31330
+ RED_CAR.yes                          1 9.5430e+10 31331
+ JOB.Student                          1 9.5432e+10 31331
- `INCOME:HOME_VAL`                    1 9.5686e+10 31331
+ EDUCATION.Masters                    1 9.5435e+10 31331
- HOME_VAL                             1 9.5695e+10 31331
+ PARENT1.Yes                          1 9.5442e+10 31331
+ JOB.Clerical                         1 9.5445e+10 31331
+ `CAR_TYPE.Panel Truck`               1 9.5446e+10 31331
- OLDCLAIM                             1 9.5700e+10 31331
+ `EDUCATION.High School`              1 9.5446e+10 31331
+ OWN.Yes                              1 9.5447e+10 31331
+ TRAVTIME                             1 9.5448e+10 31331
+ `INCOME:HOME_VAL:BLUEBOOK`           1 9.5450e+10 31331
+ `JOB.Home Maker`                     1 9.5450e+10 31331
+ URBANICITY.Urban                     1 9.5453e+10 31331
+ `INCOME:BLUEBOOK`                    1 9.5454e+10 31331
+ AGE                                  1 9.5454e+10 31331
+ `HOME_VAL:BLUEBOOK`                  1 9.5455e+10 31331
+ `JOB.Blue Collar`                    1 9.5455e+10 31331
+ `CAR_TYPE.Sports Car`                1 9.5455e+10 31331
+ KIDSDRIV                             1 9.5456e+10 31331
+ JOB.Lawyer                           1 9.5456e+10 31331
+ EDUCATION.Bachelors                  1 9.5456e+10 31331
+ YOJ                                  1 9.5456e+10 31331
+ CAR_TYPE.SUV                         1 9.5456e+10 31331
+ INCOME                               1 9.5456e+10 31331
+ `KIDSDRIV:HOMEKIDS`                  1 9.5456e+10 31331
+ TIF                                  1 9.5456e+10 31331
+ EDUCATION.PhD                        1 9.5456e+10 31331
- BLUEBOOK                             1 9.6115e+10 31337
```

# SELECT MODELS
## Model Selection Criteria
For that *classification* algorithm, we will look at accuracy, AUC, and F1, and
select the model which performs best two out of three in those metrics. For the
*regression* algorithm we will look at RMSE and MAE (since the values must
be positive) and select the model which performs best on both, Ties will be
broken by adjusted \(R^2\).

```{r setUpCompTables}
freqCompTable <- data.frame(Models = c('Model 1', 'Model 2', 'Model 3'),
                            ACC = double(3),
                            F1 = double(3),
                            AUC = double(3))
sevCompTable <- data.frame(Models = c('Model 1', 'Model 2', 'Model 3'),
                           RMSE = double(3),
                           MAE = double(3),
                           adjR2 = double(3))
```

## Model 1
### Frequency Model

```{r validateM1F}
# Model 1 Frequency:: process validation data similar to training data
tstFreq <- factor(tstX$TARGET_FLAG, levels = c(0, 1),
                  labels = c("NoClaim", "Claim"))
tstDumFreq <- dummyVars(TARGET_FLAG ~ . + OWN * HOME_VAL + KIDSDRIV * HOMEKIDS +
                          HOME_VAL * INCOME * BLUEBOOK + CLM_FREQ * OLDCLAIM +
                          MSTATUS * SEX + CAR_USE * URBANICITY - INDEX -
                          TARGET_AMT,
                        fullRank = TRUE, data = tstX)
tstXFD <- predict(tstDumFreq, newdata = tstX)
tstXFDpp <- preProcess(tstXFD, method = c('nzv', 'knnImpute'),
                       k = 3, knnSummary = median)
tstXFDI <- predict(tstXFDpp, newdata = tstXFD)

# Model 1 Frequency: predict on validation data
m1Fpred <- predict(m1FreqFit, newdata = tstXFDI)
m1FpredProb <- predict(m1FreqFit, newdata = tstXFDI, type = 'prob')

# Model 1 Frequency: Calculate accuracy statistics
m1FCM <- confusionMatrix(m1Fpred, tstFreq, mode = 'everything')
freqCompTable[1, 2] <- m1FACC <- sum(diag(m1FCM$table)) / sum(m1FCM$table)
freqCompTable[1, 3] <- m1FF1 <- m1FCM$byClass[7]
freqCompTable[1, 4] <- m1FAUC <- auc(response = tstFreq,
                                     predictor = m1FpredProb[, 1])
```

Frequency Model 1  returns an accuracy of `r round(m1FACC, 4)`, an F1 score of
`r round(m1FF1, 4)`, and an AUC of `r round(m1FAUC, 4)`.

### Severity Model

```{r validateM1S}
# Model 1 Severity: process validation data similar to training data
tstSev <- tstX[TARGET_AMT > 0, TARGET_AMT]
nobstst <- length(tstSev)
np <- summary(m1SevFit$finalModel)$df[3]
tstDumSev <- dummyVars(TARGET_AMT ~ . + OWN * HOME_VAL + KIDSDRIV * HOMEKIDS +
                          HOME_VAL * INCOME * BLUEBOOK + CLM_FREQ * OLDCLAIM +
                          MSTATUS * SEX + CAR_USE * URBANICITY - INDEX -
                          TARGET_FLAG,
                        fullRank = TRUE, data = tstX[TARGET_AMT > 0])
tstXSD <- predict(tstDumSev, newdata = tstX[TARGET_AMT > 0])
tstXSDpp <- preProcess(tstXSD, method = c('nzv', 'knnImpute'),
                       k = 3, knnSummary = median)
tstXSDI <- predict(tstXSDpp, newdata = tstXSD)

# Model 1 Severity: predict on validation data
m1Spred <- predict(m1SevFit, newdata = tstXSDI)

# Model 1 Severity: Calculate accuracy statistics
m1Ssum <- postResample(m1Spred, tstSev)
sevCompTable[1, 2] <- m1SRMSE <- m1Ssum[1]
sevCompTable[1, 3] <- m1SMAE <- m1Ssum[3]
m1SAR2 <- 1 - (1 - m1Ssum[2]) * (nobstst - 1) / (nobstst - np - 1)
sevCompTable[1, 4] <- m1SAR2
```

Severity Model 1  returns an RMSE of `r round(m1SRMSE, 1)`, an MAE of
`r round(m1SMAE, 1)`, and an adjusted \(R^2\) of `r round(m1SAR2, 4)`.

## Model 2
### Frequency Model
### Severity Model

## Model 3
### Frequency Model
### Severity Model

## Model Selection
### Frequency Model
```{r freqComp}
kable(freqCompTable, digits = 4L, caption = "Frequency Model Comparison")
```

### Severity Model
```{r sevComp}
kable(sevCompTable, digits = 4L, caption = "Severity Model Comparison")
```


# PREDICTIONS


# CODE APPENDIX
```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
```
```{r loadData}
```
```{r missingVal}
```
```{r zeroVal}
```
```{r statsN}
```
```{r graphsN}
```
```{r graphsF}
```
```{r corrgram}
```
```{r dataClean}
```
```{r trainTestSplit}
```
```{r model1addVars}
```
```{r model1DummyFreq}
```
```{r model1RunFreq}
```
```{r model1DummySev}
```
```{r model1RunSev}
```
```{r setUpCompTables}
```
```{r validateM1F}
```
```{r validateM1S}
```
```{r freqComp}
```
```{r sevComp}
```