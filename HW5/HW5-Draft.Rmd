---
title: "DATA 621 - Business Analytics and Data Mining"
subtitle: 'Fall 2020 - Group 2 - Homework #5'
author: Avraham Adler, Samantha Deokinanan, Amber Ferger, John Kellogg,
    Bryan Persaud, Jeff Shamp
date: "11/22/2020"
output:
  pdf_document:
  toc: TRUE
toc_depth: 4
urlcolor: purple
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE)
```

```{r loadData, include=FALSE}
# Load necessary libraries
library(ggplot2)
library(scales)
library(knitr)
library(caret)
library(corrplot)
library(data.table)

# Set master seed
set.seed(65408)

# Set filepaths for data ingestion
urlRemote  = "https://raw.githubusercontent.com/"
pathGithub = "aadler/DT621_Fall2020_Group2/master/HW5/data/"
fileTrain = "wine-training-data.csv"
fileTest = "wine-evaluation-data.csv"

# Read training file
DT <- fread(paste0(urlRemote, pathGithub, fileTrain))

# Number of training observations
ntrnobs <- dim(DT)[[1]]

# Get the names of the predictor variables
nmtrn <- names(DT)[-(1:2)]
nmtrnINT <- c('AcidIndex', 'LabelAppeal', 'STARS')
nmtrnDUB <- setdiff(nmtrn, nmtrnINT)
```

# ASSIGNMENT
The assignment for HW5 is to analyze and model a dataset containing
approximately 12,000 records representing commercially available wines. The
`TARGET` response variable represents the number of sample cases of wine
purchased by wine distribution companies after sampling that wine. These cases
would be used to provide tasting samples to restaurants and wine stores around
the United States. The more sample cases purchased, the more likely is a wine to
be sold at a high end restaurant.A large wine manufacturer is studying the data
in order to predict the number of wine cases ordered based upon the wine
characteristics. If the wine manufacturer can predict the number of cases, then
that manufacturer will be able to adjust their wine offering to maximize sales.

The objective of this assignment is to build a count regression model to predict
the number of cases of wine that will be sold given certain properties of the
wine. *HINT:* Sometimes, the fact that a variable is missing is actually
predictive of the target. You can only use the variables given to you (or
variables that you derive from the variables provided).

# DATA EXPLORATION
## Variables
The data is composed of the following variables:

|VARIABLE NAME|DEFINITION|THEORETICAL EFFECT|
|--|--|--|
|INDEX|Identification Variable (do not use)|None|
|TARGET|Number of Cases Purchased|None|
|AcidIndex|Proprietary method of testing total acidity of wine by using a weighted average||
|Alcohol|Alcohol Content||
|Chlorides|Chloride content of wine||
|CitricAcid|Citric Acid Content||
|Density|Density of Wine||
|FixedAcidity|Fixed Acidity of Wine||
|FreeSulfurDioxide|Sulfur Dioxide content of wine||
|LabelAppeal|Marketing Score indicating the appeal of label design for consumers. High numbers suggest customers like the label design. Negative numbers suggest customers don't like the design.|Many consumers purchase based on the visual appeal of the wine label design. Higher numbers suggest better sales.|
|ResidualSugar|Residual Sugar of wine||
|STARS|Wine rating by a team of experts. 4 Stars = Excellent, 1 Star = Poor|A high number of stars suggests high sales|
|Sulphates|Sulfate content of wine||
|TotalSulfurDioxide|Total Sulfur Dioxide of Wine||
|VolatileAcidity|Volatile Acid content of wine||
|pH|pH of wine||

There are `r ntrnobs` observations. All of these predictors are numeric, 
although `LabelAppeal`, `AcidIndex` and `STARS` all appear to be ordinal factors
and not true numerics. For the purpose of this assignment, we can treat them
as integers.

## Missing Data
There are a lot of missing values for some of the predictors.

```{r missingVal}
missingPreds <- transpose(DT[, lapply(.SD, function(x) {sum(is.na(x))}),
                             .SDcols = nmtrn],
                          keep.names = 'Predictors')
setnames(missingPreds, 'V1', 'Missing')
missingPreds[, Percentage := Missing / ntrnobs * 100]
setorder(missingPreds, -Missing)
kable(missingPreds, digits = 2L, caption = 'Predictors with Missing Observations')
```

`STARS` is especially sparse, but as noted in the assignment, this may be an
indication in and of its own. It is reasonable to assume that the vinters of a
good wine want it to be rated. If they do not submit it for rating, that may be
an indication of their lack of faith in the wine. How to factor this into the
analysis will be decided individually by the modelers in this assignment. The
other missing variables are all less than 10%, and their handling via imputation
or otherwise will be done on a model-by-model basis as well.

## Summary Statistics and Graphs
As all of the data are numeric, we can investigate the distributions of the
predictors both tabularly and graphically.

The numeric predictor variables have the following summary statistics, ignoring
missing values:

```{r statsN}
# Isolate numeric only predictors
predictorDT <- DT[, .SD, .SDcols = nmtrn]

# Melt them from wide to long format
predictorDTM <- melt(predictorDT, variable.name = 'metric',
                     value.name = 'value',  variable.factor = FALSE,
                     id.vars = NULL)

# Calculate summary statistics
statsN <- predictorDTM[, .(Mean = mean(value, na.rm = TRUE),
                           SD = sd(value, na.rm = TRUE),
                           Min = min(value, na.rm = TRUE),
                           Q1 = quantile(value, prob = 0.25, na.rm = TRUE),
                           Median = median(value, na.rm = TRUE),
                           Q3 = quantile(value, prob = 0.75, na.rm = TRUE),
                           Max = max(value, na.rm = TRUE),
                           IQR = IQR(value, na.rm = TRUE)), keyby = 'metric']

# Print the table
kable(statsN, digits = 3L, align = 'r',
      caption = "Summary Statistitics for Numeric Variables")
```

A kernel-smoothed density plot of the distributions of the non-integer numeric
predictors is below, followed by a histogram of the integral-valued predictors.

```{r graphsD, fig.height=5, fig.width=7}
# Using epanechnikov kernel to generate kernel-smoothed densities
ggplot(predictorDTM[!is.na(metric) & metric %chin% nmtrnDUB], aes(x = value)) +
  geom_density(kernel = 'epanechnikov') +
  facet_wrap( ~ metric, scales = 'free') +
  ggtitle('Kernel-smoothed Density of Numeric Predictors')
```

The numeric predictors all look to be basically symmetrical, but non-Gaussian in
that there is a strong spike near the median, but the tails on either side are
thicker than would be for a normal distribution with that low of a standard
deviation. This is also why a boxplot would be a poor graphical indicator, as
the spike at the medians would lead to a compressed inter-quartile range and a
plethora of outliers.

```{r graphsH, fig.height=2, fig.width=7}
# Freedman-Diaconis rule for bin widths
FDbin <- function(x) {
  result <- 2 * IQR(x, na.rm = TRUE) / (length(x) ^ (1 / 3))
  return(ifelse(result == 0, 0.5, result))
}
# Generate histogram
ggplot(predictorDTM[!is.na(metric) & metric %chin% nmtrnINT], aes(x = value)) +
  geom_histogram(binwidth = FDbin, fill = 'indianred4') +
  facet_wrap( ~ metric, scales = 'free') +
  ggtitle('Histogram of Integral Predictors')
```

Of these three, `LabelAppeal` seems to be the most "normal" of the lot; `STARS`
and `AcidIndex` look to be more Poisson in shape.

## Correlations
The corrgram below graphically represents the correlations between the numeric
predictor variables, when ignoring the missing variables.

```{r corrgram, fig.width=5, fig.height=6.5}
# Create corrgram
corrplot::corrplot(cor(DT[, ..nmtrn], use = 'complete.obs'),
         method = 'ellipse', type = 'lower', order = 'hclust',
         hclust.method = 'ward.D2')
```

There is very little correlation between the variables. The only pairs with some
level correlation are:

  * `STARS` being positively correlated with `LabelAppeal`
    * This is interesting. Could it be that wine connoisseurs are impacted by
    the visual appearance of the label and not just the flavor?
  * `AcidIndex` having some positive correlation with `FixedAcidity`
    * One may have suspected a higher correlation, to be frank.
  * `AcidIndex` having some *negative* correlation with `STARS`
    * Wine reviewers may not like too much acidity, it seems.
    
# DATA PREPARATION
First, preparation necessary for all the models equally will be performed. The
subsequent imputation and feature generation, if necessary will be discussed in
a separate subsection for each modeler.

## Training & Testing Split
All the models will be trained on the same approximately 70% of the training
set, reserving 30% for validation of which model to select for the count
estimation on the supplied evaluation set.

```{r trainTestSplit}
# Create training and testing split
set.seed(1004)
trnIDX <- createDataPartition(DT$TARGET, p = 0.7)
trnX <- DT[trnIDX$Resample1, ]
tstX <- DT[!trnIDX$Resample1, ]
```

## Modeler # 1
### Missing Data
The missing data can be split into two groups: `STARS` and the rest. For all the
others, I do not think there is signal encoded in the "missingness" and thus
will use some form of imputation. `STARS` is different as discussed in the DATA
EXPLORATION section. Therefore, I will create a new feature called `Rated` which
will be true if `STARS` is missing, and then only use this variable and its
interaction with `STARS` in the model, and not `STARS` by itself. 

```{r model1addVars}
# Copy the training set to leave a pristine version for others
m1trnX <- copy(trnX)

# Add the "rated" factor variable
m1trnX[, Rated := factor(ifelse(is.na(STARS), 'Unrated', 'Rated'),
                         levels = c('Unrated', 'Rated'),
                         labels = c('Unrated', 'Rated'))]
```

### Imputation
Imputation will be handled through bagging. Instead of looking at a nearest
neighbors approach, which also requires centering and scaling, once can create a
set of bagged trees. As per Kuhn (2019):

>*For each predictor in the data, a bagged tree is created using all of the*
*other predictors in the training set. When a new sample has a missing*
*predictor value, the bagged model is used to predict the value. While, in*
*theory, this is a more powerful method of imputing, the computational costs*
*are much higher than the nearest neighbor technique.*

The bagged trees will use `STARS` as a predictor, as that contains valuable
information, but prior to the imputation, the missing `STARS` values will be
replaced by 0 so as not to be imputed, as per the explanation above. The
preprocessing will also check for near-zero value predictors.

```{r model1impute}
# Create bagged-tree imputation model
m1trnXi <- preProcess(m1trnX, method =c('nzv', 'bagImpute'))

# Replace missing STARS with 0s
m1trnX[is.na(STARS), STARS := 0L]

# Impute the remaining NAs
m1trnXimp <- predict(m1trnXi, newdata = m1trnX)
```

It will be instructive to compare the shapes of the distributions after
imputation to those before imputation.

```{r m1postImputeD, fig.height=5, fig.width=7}
# Isolate numeric only predictors
m1predictorDT <- m1trnXimp[, .SD, .SDcols = nmtrn]

# Melt them from wide to long format
m1predictorDTM <- melt(m1predictorDT, variable.name = 'metric',
                     value.name = 'value',  variable.factor = FALSE,
                     id.vars = NULL)

# Using epanechnikov kernel to generate kernel-smoothed densities
ggplot(predictorDTM[metric %chin% nmtrnDUB], aes(x = value)) +
  geom_density(kernel = 'epanechnikov') +
  facet_wrap( ~ metric, scales = 'free') +
  ggtitle('Kernel-smoothed Density of Numeric Predictors')
```

Thankfully, none of the shapes appears to have changed significantly, which
implies the imputation was in line with the original distributions. Now for the
histograms.

```{r m1postImputeH, fig.height=2, fig.width=7}
# Generate histogram
ggplot(m1predictorDTM[metric %chin% nmtrnINT], aes(x = value)) +
  geom_histogram(binwidth = FDbin, fill = 'indianred4') +
  facet_wrap( ~ metric, scales = 'free') +
  ggtitle('Histogram of Integral Predictors')
```

Here too, `AcidIndex` and `LabelAppeal` look very similar to their
pre-imputation distribution. What stands out is `STARS`. Both the Poisson and
the negative binomial models are either unimodal or have to consecutive values
sharing the mode, due to their inherent nature as discrete disctibutions. What
is seen here is that 1 star is empirically less common than 0 (unrated) or 2
stars. On the one hand, this could simply be noise (process variance) or
parameter error (finite sample size). On the other, it could indicate the need
for a zero-inflated version of the counting distributions.

# BUILD MODELS
## Modeler # 1
Each of the models will follow a similar format, with only the family changing.
Each model will start with the saturated model including all the predictors,
***except*** for `STARS` which will be replaced with the interaction between
`Rated` and `STARS`. A forward and backwards stepwise procedure based on AIC
will be used, and the model with the lowest AIC on the training set will be the
selected to be tested against the testing set. Using stepAIC precludes the use
of k-fold cross validation.

```{r m1TrainControl}
# All Modeler 1 models will use stepAIC so turn off cross-validation
trc <- trainControl(method = 'none')
```

### Poisson Model

```{r m1Poisson}
set.seed(350047)
m1PFit <- train(TARGET ~ . - INDEX - STARS + Rated:STARS, data = m1trnXimp,
                trControl = trc, method = 'glmStepAIC',
                family = poisson(link = 'log'), direction = 'both', trace = 0)
# Print results
kable(summary(m1PFit$finalModel)$coefficients, digits = 3L,
      caption = "Model 1 Poisson Regression Output")
```



```
                     Df Deviance   AIC
<none>                    9654.5 31998
- Sulphates           1   9657.1 31998
+ Density             1   9654.1 31999
+ ResidualSugar       1   9654.2 31999
- Alcohol             1   9658.3 32000
+ CitricAcid          1   9654.4 32000
+ FixedAcidity        1   9654.4 32000
- pH                  1   9659.0 32000
- Chlorides           1   9659.5 32001
- FreeSulfurDioxide   1   9659.7 32001
- TotalSulfurDioxide  1   9670.3 32012
- VolatileAcidity     1   9670.9 32012
- AcidIndex           1   9880.9 32222
- LabelAppeal         1  10102.7 32444
- `STARS:RatedRated`  1  10335.1 32676
- RatedRated          1  10337.5 32679
```




# SELECT MODELS
## Model Selection Criteria
We will look at RMSE and AIC as our metrics and select the model which performs
best on both, Ties will be broken by \(R^2\).

# References

  * Kuhn, M. (2019, March 27). *The `caret` Package*.
  https://topepo.github.io/caret/pre-processing.html#imputation

# CODE APPENDIX
```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
```
```{r loadData}
```
```{r missingVal}
```
```{r statsN}
```
```{r graphsD}
```
```{r graphsH}
```
```{r corrgram}
```
```{r trainTestSplit}
```
```{r model1addVars}
```
```{r model1impute}
```
```{r m1postImputeD}
```
```{r m1postImputeH}
```
```{r m1TrainControl}
```
